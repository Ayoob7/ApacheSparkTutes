{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "metadata": {
        "id": "4Ho4DEGs2Ixu",
        "outputId": "2d787c5a-05e8-4f80-cdd4-20d3fac3df84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "import pyspark.sql  as pyspark_sql\n",
        "import pyspark.sql.types as pyspark_types\n",
        "import pyspark.sql.functions  as F\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql.functions import row_number, desc\n",
        "\n",
        "# create the session\n",
        "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
        "\n",
        "# create the context\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = pyspark_sql.SparkSession.builder.getOrCreate()"
      ],
      "metadata": {
        "id": "r_IExLdN2OFT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# User Defined Function (UDF) in PySpark\n",
        "\n"
      ],
      "metadata": {
        "id": "mgP04tczLZYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "# Creating a dummy dataset\n",
        "data = [\n",
        "    ('John', 32, 'New York', 70000.0),\n",
        "    ('Jane', 28, 'Los Angeles', 65000.0),\n",
        "    ('Mike', 45, 'Chicago', 80000.0),\n",
        "    ('Emily', 35, 'New York', 75000.0),\n",
        "    ('David', 29, 'San Francisco', 90000.0),\n",
        "    ('Sarah', 41, 'Chicago', 85000.0)\n",
        "]\n",
        "\n",
        "columns = ['name', 'age', 'city', 'salary']\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1guAzgDKqXI",
        "outputId": "e3723616-1aca-415d-876c-704ba52eaaa5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+-------------+-------+\n",
            "| name|age|         city| salary|\n",
            "+-----+---+-------------+-------+\n",
            "| John| 32|     New York|70000.0|\n",
            "| Jane| 28|  Los Angeles|65000.0|\n",
            "| Mike| 45|      Chicago|80000.0|\n",
            "|Emily| 35|     New York|75000.0|\n",
            "|David| 29|San Francisco|90000.0|\n",
            "|Sarah| 41|      Chicago|85000.0|\n",
            "+-----+---+-------------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a UDF to calculate the tax based on the salary\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "def calculate_tax(salary):\n",
        "    if salary <= 50000:\n",
        "        return salary * 0.1\n",
        "    elif salary > 50000 and salary <= 75000:\n",
        "        return salary * 0.15\n",
        "    else:\n",
        "        return salary * 0.2\n",
        "\n",
        "calculate_tax_udf = udf(calculate_tax, DoubleType())\n",
        "df = df.withColumn('tax', calculate_tax_udf('salary'))\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gARvbnjsSR2N",
        "outputId": "3f2d71e3-62ca-4ede-8280-ea9d74b68d16"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+-------------+-------+-------+\n",
            "| name|age|         city| salary|    tax|\n",
            "+-----+---+-------------+-------+-------+\n",
            "| John| 32|     New York|70000.0|10500.0|\n",
            "| Jane| 28|  Los Angeles|65000.0| 9750.0|\n",
            "| Mike| 45|      Chicago|80000.0|16000.0|\n",
            "|Emily| 35|     New York|75000.0|11250.0|\n",
            "|David| 29|San Francisco|90000.0|18000.0|\n",
            "|Sarah| 41|      Chicago|85000.0|17000.0|\n",
            "+-----+---+-------------+-------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using UDF with PySpark DataFrame withColumn()\n",
        "def upperCase(str):\n",
        "    return str.upper()\n",
        "\n",
        "upperCaseUDF = udf(lambda z:upperCase(z),StringType())\n",
        "\n",
        "df.withColumn(\"Cureated Name\", upperCaseUDF(col(\"Name\"))) \\\n",
        ".show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJMzoJpESe3c",
        "outputId": "1203a919-6c1e-4db4-97d4-a8dee8d97f0d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------+-------------+\n",
            "|Seqno|Name        |Cureated Name|\n",
            "+-----+------------+-------------+\n",
            "|1    |john jones  |JOHN JONES   |\n",
            "|2    |tracey smith|TRACEY SMITH |\n",
            "|3    |amy sanders |AMY SANDERS  |\n",
            "+-----+------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a UDF to capitalize the first letter of each name\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "def capitalize_name(name):\n",
        "    return name.title()\n",
        "\n",
        "capitalize_name_udf = udf(capitalize_name, StringType())\n",
        "df = df.withColumn('capitalized_name', capitalize_name_udf('name'))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKnbfajteGGn",
        "outputId": "fbab0a56-2691-490c-c1cc-d2259537e9c7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+-------------+-------+-------+----------------+\n",
            "| name|age|         city| salary|    tax|capitalized_name|\n",
            "+-----+---+-------------+-------+-------+----------------+\n",
            "| John| 32|     New York|70000.0|10500.0|            John|\n",
            "| Jane| 28|  Los Angeles|65000.0| 9750.0|            Jane|\n",
            "| Mike| 45|      Chicago|80000.0|16000.0|            Mike|\n",
            "|Emily| 35|     New York|75000.0|11250.0|           Emily|\n",
            "|David| 29|San Francisco|90000.0|18000.0|           David|\n",
            "|Sarah| 41|      Chicago|85000.0|17000.0|           Sarah|\n",
            "+-----+---+-------------+-------+-------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a UDF to calculate the age group based on the age\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "def calculate_age_group(age):\n",
        "    if age <= 30:\n",
        "        return 'Young'\n",
        "    elif age > 30 and age <= 40:\n",
        "        return 'Adult'\n",
        "    else:\n",
        "        return 'Senior'\n",
        "\n",
        "calculate_age_group_udf = udf(calculate_age_group, StringType())\n",
        "df = df.withColumn('age_group', calculate_age_group_udf('age'))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7Pwje6_eSIP",
        "outputId": "22881e9e-3c8a-4c20-a64f-cc5f0cef2540"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+-------------+-------+-------+----------------+---------+\n",
            "| name|age|         city| salary|    tax|capitalized_name|age_group|\n",
            "+-----+---+-------------+-------+-------+----------------+---------+\n",
            "| John| 32|     New York|70000.0|10500.0|            John|    Adult|\n",
            "| Jane| 28|  Los Angeles|65000.0| 9750.0|            Jane|    Young|\n",
            "| Mike| 45|      Chicago|80000.0|16000.0|            Mike|   Senior|\n",
            "|Emily| 35|     New York|75000.0|11250.0|           Emily|    Adult|\n",
            "|David| 29|San Francisco|90000.0|18000.0|           David|    Young|\n",
            "|Sarah| 41|      Chicago|85000.0|17000.0|           Sarah|   Senior|\n",
            "+-----+---+-------------+-------+-------+----------------+---------+\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}