{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "metadata": {
        "id": "4Ho4DEGs2Ixu",
        "outputId": "be6b49e2-e944-4a06-c08c-7a71609a838e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=46331e91cac2c62747a8f6c89d0fbe93d6086190bd5ac7a58a7c68dc76d08dfd\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n",
            "The following additional packages will be installed:\n",
            "  libxtst6 openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra fonts-nanum fonts-ipafont-gothic\n",
            "  fonts-ipafont-mincho fonts-wqy-microhei fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  libxtst6 openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 3 newly installed, 0 to remove and 38 not upgraded.\n",
            "Need to get 39.7 MB of archives.\n",
            "After this operation, 144 MB of additional disk space will be used.\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "(Reading database ... 121752 files and directories currently installed.)\n",
            "Preparing to unpack .../libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u402-ga-2ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u402-ga-2ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u402-ga-2ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u402-ga-2ubuntu1~22.04) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u402-ga-2ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u402-ga-2ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "import pyspark.sql  as pyspark_sql\n",
        "import pyspark.sql.types as pyspark_types\n",
        "import pyspark.sql.functions  as F\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql.functions import row_number, desc\n",
        "\n",
        "# create the session\n",
        "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
        "\n",
        "# create the context\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = pyspark_sql.SparkSession.builder.getOrCreate()"
      ],
      "metadata": {
        "id": "r_IExLdN2OFT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification"
      ],
      "metadata": {
        "id": "mgP04tczLZYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "data = load_iris()\n",
        "cols = [i.replace('(cm)','').strip().replace(' ','_') for i in data.feature_names] + ['label'] # Column name cleanup\n",
        "pdf = pd.DataFrame(np.c_[data.data, data.target], columns=cols)\n",
        "df = spark.createDataFrame(pdf, [\"feature1\", \"feature2\", \"feature3\", \"feature4\", \"label\"])\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1guAzgDKqXI",
        "outputId": "e6a83e11-c3b3-443a-8ac6-e9aa8e1611ad"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+--------+--------+-----+\n",
            "|feature1|feature2|feature3|feature4|label|\n",
            "+--------+--------+--------+--------+-----+\n",
            "|     5.1|     3.5|     1.4|     0.2|  0.0|\n",
            "|     4.9|     3.0|     1.4|     0.2|  0.0|\n",
            "|     4.7|     3.2|     1.3|     0.2|  0.0|\n",
            "|     4.6|     3.1|     1.5|     0.2|  0.0|\n",
            "|     5.0|     3.6|     1.4|     0.2|  0.0|\n",
            "|     5.4|     3.9|     1.7|     0.4|  0.0|\n",
            "|     4.6|     3.4|     1.4|     0.3|  0.0|\n",
            "|     5.0|     3.4|     1.5|     0.2|  0.0|\n",
            "|     4.4|     2.9|     1.4|     0.2|  0.0|\n",
            "|     4.9|     3.1|     1.5|     0.1|  0.0|\n",
            "|     5.4|     3.7|     1.5|     0.2|  0.0|\n",
            "|     4.8|     3.4|     1.6|     0.2|  0.0|\n",
            "|     4.8|     3.0|     1.4|     0.1|  0.0|\n",
            "|     4.3|     3.0|     1.1|     0.1|  0.0|\n",
            "|     5.8|     4.0|     1.2|     0.2|  0.0|\n",
            "|     5.7|     4.4|     1.5|     0.4|  0.0|\n",
            "|     5.4|     3.9|     1.3|     0.4|  0.0|\n",
            "|     5.1|     3.5|     1.4|     0.3|  0.0|\n",
            "|     5.7|     3.8|     1.7|     0.3|  0.0|\n",
            "|     5.1|     3.8|     1.5|     0.3|  0.0|\n",
            "+--------+--------+--------+--------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert label (string) to integer for classification\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(df)\n",
        "df = labelIndexer.transform(df)\n",
        "df.show()"
      ],
      "metadata": {
        "id": "Ss3G-mrY2kbg",
        "outputId": "b2e9ccde-bfb7-4e54-acb6-d489b46928a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+--------+--------+-----+------------+\n",
            "|feature1|feature2|feature3|feature4|label|indexedLabel|\n",
            "+--------+--------+--------+--------+-----+------------+\n",
            "|     5.1|     3.5|     1.4|     0.2|  0.0|         0.0|\n",
            "|     4.9|     3.0|     1.4|     0.2|  0.0|         0.0|\n",
            "|     4.7|     3.2|     1.3|     0.2|  0.0|         0.0|\n",
            "|     4.6|     3.1|     1.5|     0.2|  0.0|         0.0|\n",
            "|     5.0|     3.6|     1.4|     0.2|  0.0|         0.0|\n",
            "|     5.4|     3.9|     1.7|     0.4|  0.0|         0.0|\n",
            "|     4.6|     3.4|     1.4|     0.3|  0.0|         0.0|\n",
            "|     5.0|     3.4|     1.5|     0.2|  0.0|         0.0|\n",
            "|     4.4|     2.9|     1.4|     0.2|  0.0|         0.0|\n",
            "|     4.9|     3.1|     1.5|     0.1|  0.0|         0.0|\n",
            "|     5.4|     3.7|     1.5|     0.2|  0.0|         0.0|\n",
            "|     4.8|     3.4|     1.6|     0.2|  0.0|         0.0|\n",
            "|     4.8|     3.0|     1.4|     0.1|  0.0|         0.0|\n",
            "|     4.3|     3.0|     1.1|     0.1|  0.0|         0.0|\n",
            "|     5.8|     4.0|     1.2|     0.2|  0.0|         0.0|\n",
            "|     5.7|     4.4|     1.5|     0.4|  0.0|         0.0|\n",
            "|     5.4|     3.9|     1.3|     0.4|  0.0|         0.0|\n",
            "|     5.1|     3.5|     1.4|     0.3|  0.0|         0.0|\n",
            "|     5.7|     3.8|     1.7|     0.3|  0.0|         0.0|\n",
            "|     5.1|     3.8|     1.5|     0.3|  0.0|         0.0|\n",
            "+--------+--------+--------+--------+-----+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and test sets\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "assembler = VectorAssembler(inputCols=[\"feature1\", \"feature2\", \"feature3\", \"feature4\"], outputCol=\"features\")\n",
        "\n",
        "df = assembler.transform(df)\n",
        "(trainingData, testData) = df.randomSplit([0.7, 0.3])\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "id": "_Or2BZJ92q7_",
        "outputId": "ad6a2486-f530-4041-98c3-35bfae53f3fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+--------+--------+-----+------------+-----------------+\n",
            "|feature1|feature2|feature3|feature4|label|indexedLabel|         features|\n",
            "+--------+--------+--------+--------+-----+------------+-----------------+\n",
            "|     5.1|     3.5|     1.4|     0.2|  0.0|         0.0|[5.1,3.5,1.4,0.2]|\n",
            "|     4.9|     3.0|     1.4|     0.2|  0.0|         0.0|[4.9,3.0,1.4,0.2]|\n",
            "|     4.7|     3.2|     1.3|     0.2|  0.0|         0.0|[4.7,3.2,1.3,0.2]|\n",
            "|     4.6|     3.1|     1.5|     0.2|  0.0|         0.0|[4.6,3.1,1.5,0.2]|\n",
            "|     5.0|     3.6|     1.4|     0.2|  0.0|         0.0|[5.0,3.6,1.4,0.2]|\n",
            "|     5.4|     3.9|     1.7|     0.4|  0.0|         0.0|[5.4,3.9,1.7,0.4]|\n",
            "|     4.6|     3.4|     1.4|     0.3|  0.0|         0.0|[4.6,3.4,1.4,0.3]|\n",
            "|     5.0|     3.4|     1.5|     0.2|  0.0|         0.0|[5.0,3.4,1.5,0.2]|\n",
            "|     4.4|     2.9|     1.4|     0.2|  0.0|         0.0|[4.4,2.9,1.4,0.2]|\n",
            "|     4.9|     3.1|     1.5|     0.1|  0.0|         0.0|[4.9,3.1,1.5,0.1]|\n",
            "|     5.4|     3.7|     1.5|     0.2|  0.0|         0.0|[5.4,3.7,1.5,0.2]|\n",
            "|     4.8|     3.4|     1.6|     0.2|  0.0|         0.0|[4.8,3.4,1.6,0.2]|\n",
            "|     4.8|     3.0|     1.4|     0.1|  0.0|         0.0|[4.8,3.0,1.4,0.1]|\n",
            "|     4.3|     3.0|     1.1|     0.1|  0.0|         0.0|[4.3,3.0,1.1,0.1]|\n",
            "|     5.8|     4.0|     1.2|     0.2|  0.0|         0.0|[5.8,4.0,1.2,0.2]|\n",
            "|     5.7|     4.4|     1.5|     0.4|  0.0|         0.0|[5.7,4.4,1.5,0.4]|\n",
            "|     5.4|     3.9|     1.3|     0.4|  0.0|         0.0|[5.4,3.9,1.3,0.4]|\n",
            "|     5.1|     3.5|     1.4|     0.3|  0.0|         0.0|[5.1,3.5,1.4,0.3]|\n",
            "|     5.7|     3.8|     1.7|     0.3|  0.0|         0.0|[5.7,3.8,1.7,0.3]|\n",
            "|     5.1|     3.8|     1.5|     0.3|  0.0|         0.0|[5.1,3.8,1.5,0.3]|\n",
            "+--------+--------+--------+--------+-----+------------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DecisionTreeClassifier model\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "\n",
        "# Train the model on the training data\n",
        "model = dt.fit(trainingData)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.transform(testData)\n",
        "\n",
        "# Evaluate the model performance (optional)\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "# Stop the SparkSession\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "kRSIQSA72-_w",
        "outputId": "7b61bb92-0859-4d3c-891b-4278d01a0071",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9069767441860465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression"
      ],
      "metadata": {
        "id": "bP2jzjnx3NhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Fetch California housing data with feature names\n",
        "housing = fetch_california_housing(as_frame=True)\n",
        "data_df = housing.frame  # data_df is a pandas DataFrame\n",
        "\n",
        "# SparkSession creation (replace with your Spark configuration)\n",
        "spark = SparkSession.builder.appName(\"CaliforniaHousing\").getOrCreate()\n",
        "\n",
        "# Convert pandas DataFrame to Spark DataFrame\n",
        "spark_df = spark.createDataFrame(data_df, [\"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\", \"x7\", \"x8\", \"y\"])\n",
        "\n",
        "# Now you can use spark_df for further processing in Spark\n",
        "spark_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwfSmwjtLtcJ",
        "outputId": "e6a58f5a-3422-4b3c-b1e3-e57bcdc62168"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+------------------+------------------+------+------------------+-----+-------+-----+\n",
            "|    x1|  x2|                x3|                x4|    x5|                x6|   x7|     x8|    y|\n",
            "+------+----+------------------+------------------+------+------------------+-----+-------+-----+\n",
            "|8.3252|41.0| 6.984126984126984|1.0238095238095237| 322.0|2.5555555555555554|37.88|-122.23|4.526|\n",
            "|8.3014|21.0| 6.238137082601054|0.9718804920913884|2401.0| 2.109841827768014|37.86|-122.22|3.585|\n",
            "|7.2574|52.0| 8.288135593220339| 1.073446327683616| 496.0|2.8022598870056497|37.85|-122.24|3.521|\n",
            "|5.6431|52.0|5.8173515981735155|1.0730593607305936| 558.0| 2.547945205479452|37.85|-122.25|3.413|\n",
            "|3.8462|52.0| 6.281853281853282|1.0810810810810811| 565.0|2.1814671814671813|37.85|-122.25|3.422|\n",
            "|4.0368|52.0| 4.761658031088083|1.1036269430051813| 413.0| 2.139896373056995|37.85|-122.25|2.697|\n",
            "|3.6591|52.0|4.9319066147859925|0.9513618677042801|1094.0|2.1284046692607004|37.84|-122.25|2.992|\n",
            "|  3.12|52.0| 4.797527047913447| 1.061823802163833|1157.0|1.7882534775888717|37.84|-122.25|2.414|\n",
            "|2.0804|42.0| 4.294117647058823|1.1176470588235294|1206.0| 2.026890756302521|37.84|-122.26|2.267|\n",
            "|3.6912|52.0| 4.970588235294118|0.9901960784313726|1551.0| 2.172268907563025|37.84|-122.25|2.611|\n",
            "|3.2031|52.0| 5.477611940298507|1.0796019900497513| 910.0| 2.263681592039801|37.85|-122.26|2.815|\n",
            "|3.2705|52.0| 4.772479564032698|1.0245231607629428|1504.0|2.0490463215258856|37.85|-122.26|2.418|\n",
            "| 3.075|52.0| 5.322649572649572|1.0128205128205128|1098.0|2.3461538461538463|37.85|-122.26|2.135|\n",
            "|2.6736|52.0|               4.0|1.0977011494252873| 345.0|1.9827586206896552|37.84|-122.26|1.913|\n",
            "|1.9167|52.0| 4.262903225806451|1.0096774193548388|1212.0|1.9548387096774194|37.85|-122.26|1.592|\n",
            "| 2.125|50.0| 4.242424242424242| 1.071969696969697| 697.0| 2.640151515151515|37.85|-122.26|  1.4|\n",
            "| 2.775|52.0|5.9395770392749245|1.0483383685800605| 793.0| 2.395770392749245|37.85|-122.27|1.525|\n",
            "|2.1202|52.0| 4.052805280528053| 0.966996699669967| 648.0|2.1386138613861387|37.85|-122.27|1.555|\n",
            "|1.9911|50.0| 5.343675417661098|1.0859188544152745| 990.0|2.3627684964200477|37.84|-122.26|1.587|\n",
            "|2.6033|52.0| 5.465454545454546|1.0836363636363637| 690.0|2.5090909090909093|37.84|-122.27|1.629|\n",
            "+------+----+------------------+------------------+------+------------------+-----+-------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assemble features into a single vector\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "assembler = VectorAssembler(inputCols=[\"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\", \"x7\", \"x8\"], outputCol=\"features\")\n",
        "spark_df = assembler.transform(spark_df)\n",
        "\n",
        "spark_df = spark_df.withColumnRenamed(\"y\", \"label\")\n",
        "\n",
        "spark_df.show()"
      ],
      "metadata": {
        "id": "7jQjwL5C5t0v",
        "outputId": "c4a15d8d-09a2-4d30-8785-3b07364d9ec8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+------------------+------------------+------+------------------+-----+-------+-----+--------------------+\n",
            "|    x1|  x2|                x3|                x4|    x5|                x6|   x7|     x8|label|            features|\n",
            "+------+----+------------------+------------------+------+------------------+-----+-------+-----+--------------------+\n",
            "|8.3252|41.0| 6.984126984126984|1.0238095238095237| 322.0|2.5555555555555554|37.88|-122.23|4.526|[8.3252,41.0,6.98...|\n",
            "|8.3014|21.0| 6.238137082601054|0.9718804920913884|2401.0| 2.109841827768014|37.86|-122.22|3.585|[8.3014,21.0,6.23...|\n",
            "|7.2574|52.0| 8.288135593220339| 1.073446327683616| 496.0|2.8022598870056497|37.85|-122.24|3.521|[7.2574,52.0,8.28...|\n",
            "|5.6431|52.0|5.8173515981735155|1.0730593607305936| 558.0| 2.547945205479452|37.85|-122.25|3.413|[5.6431,52.0,5.81...|\n",
            "|3.8462|52.0| 6.281853281853282|1.0810810810810811| 565.0|2.1814671814671813|37.85|-122.25|3.422|[3.8462,52.0,6.28...|\n",
            "|4.0368|52.0| 4.761658031088083|1.1036269430051813| 413.0| 2.139896373056995|37.85|-122.25|2.697|[4.0368,52.0,4.76...|\n",
            "|3.6591|52.0|4.9319066147859925|0.9513618677042801|1094.0|2.1284046692607004|37.84|-122.25|2.992|[3.6591,52.0,4.93...|\n",
            "|  3.12|52.0| 4.797527047913447| 1.061823802163833|1157.0|1.7882534775888717|37.84|-122.25|2.414|[3.12,52.0,4.7975...|\n",
            "|2.0804|42.0| 4.294117647058823|1.1176470588235294|1206.0| 2.026890756302521|37.84|-122.26|2.267|[2.0804,42.0,4.29...|\n",
            "|3.6912|52.0| 4.970588235294118|0.9901960784313726|1551.0| 2.172268907563025|37.84|-122.25|2.611|[3.6912,52.0,4.97...|\n",
            "|3.2031|52.0| 5.477611940298507|1.0796019900497513| 910.0| 2.263681592039801|37.85|-122.26|2.815|[3.2031,52.0,5.47...|\n",
            "|3.2705|52.0| 4.772479564032698|1.0245231607629428|1504.0|2.0490463215258856|37.85|-122.26|2.418|[3.2705,52.0,4.77...|\n",
            "| 3.075|52.0| 5.322649572649572|1.0128205128205128|1098.0|2.3461538461538463|37.85|-122.26|2.135|[3.075,52.0,5.322...|\n",
            "|2.6736|52.0|               4.0|1.0977011494252873| 345.0|1.9827586206896552|37.84|-122.26|1.913|[2.6736,52.0,4.0,...|\n",
            "|1.9167|52.0| 4.262903225806451|1.0096774193548388|1212.0|1.9548387096774194|37.85|-122.26|1.592|[1.9167,52.0,4.26...|\n",
            "| 2.125|50.0| 4.242424242424242| 1.071969696969697| 697.0| 2.640151515151515|37.85|-122.26|  1.4|[2.125,50.0,4.242...|\n",
            "| 2.775|52.0|5.9395770392749245|1.0483383685800605| 793.0| 2.395770392749245|37.85|-122.27|1.525|[2.775,52.0,5.939...|\n",
            "|2.1202|52.0| 4.052805280528053| 0.966996699669967| 648.0|2.1386138613861387|37.85|-122.27|1.555|[2.1202,52.0,4.05...|\n",
            "|1.9911|50.0| 5.343675417661098|1.0859188544152745| 990.0|2.3627684964200477|37.84|-122.26|1.587|[1.9911,50.0,5.34...|\n",
            "|2.6033|52.0| 5.465454545454546|1.0836363636363637| 690.0|2.5090909090909093|37.84|-122.27|1.629|[2.6033,52.0,5.46...|\n",
            "+------+----+------------------+------------------+------+------------------+-----+-------+-----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a LinearRegression model\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "lr = LinearRegression()\n",
        "\n",
        "# Train the model on the data\n",
        "model = lr.fit(spark_df)\n"
      ],
      "metadata": {
        "id": "UZu-wmPU44Xb"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on new data\n",
        "predictions = model.transform(spark_df)\n",
        "predictions.select(\"features\", \"prediction\").show()\n",
        "\n",
        "# Print the model coefficients and intercept\n",
        "print(\"Coefficients:\", model.coefficients)\n",
        "print(\"Intercept:\", model.intercept)\n",
        "\n",
        "# Stop the SparkSession\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "QpDLVT-E6AjP",
        "outputId": "4ede22b9-d6f8-44b6-b183-443cc881cd6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+\n",
            "|            features|        prediction|\n",
            "+--------------------+------------------+\n",
            "|[8.3252,41.0,6.98...| 4.131649827074092|\n",
            "|[8.3014,21.0,6.23...|3.9766064386950646|\n",
            "|[7.2574,52.0,8.28...| 3.676570941048361|\n",
            "|[5.6431,52.0,5.81...|3.2415984958222523|\n",
            "|[3.8462,52.0,6.28...| 2.413587434987811|\n",
            "|[4.0368,52.0,4.76...|2.6752770171934017|\n",
            "|[3.6591,52.0,4.93...|2.3953942948275326|\n",
            "|[3.12,52.0,4.7975...|2.2466875187591526|\n",
            "|[2.0804,42.0,4.29...|1.7916266674291492|\n",
            "|[3.6912,52.0,4.97...| 2.428328072362106|\n",
            "|[3.2031,52.0,5.47...|2.2207706646639096|\n",
            "|[3.2705,52.0,4.77...|2.2888013257793673|\n",
            "|[3.075,52.0,5.322...|2.1373228456041247|\n",
            "|[2.6736,52.0,4.0,...|2.1673205731827423|\n",
            "|[1.9167,52.0,4.26...|1.7442360667615304|\n",
            "|[2.125,50.0,4.242...|1.8581610556018404|\n",
            "|[2.775,52.0,5.939...|1.9683863539533917|\n",
            "|[2.1202,52.0,4.05...|1.8340113729812018|\n",
            "|[1.9911,50.0,5.34...|1.6945958066558475|\n",
            "|[2.6033,52.0,5.46...|1.9712530540102122|\n",
            "+--------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Coefficients: [0.4366932931452286,0.009435778034049326,-0.10732204140230056,0.6450656935559659,-3.976389419491232e-06,-0.0037865426550974884,-0.42131437747913,-0.43451375461943875]\n",
            "Intercept: -36.94192020232348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering"
      ],
      "metadata": {
        "id": "FVkCKFQ0PRaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from pyspark.ml.clustering import KMeans\n",
        "wine = load_wine()\n",
        "data = wine.data  # Feature matrix\n",
        "target = wine.target  # Target labels (wine types)"
      ],
      "metadata": {
        "id": "9vp8D7kBPToO"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# SparkSession creation (replace with your Spark configuration)\n",
        "spark = SparkSession.builder.appName(\"WineKMeans\").getOrCreate()\n",
        "\n",
        "wine_cols = ['_1',\n",
        " '_2',\n",
        " '_3',\n",
        " '_4',\n",
        " '_5',\n",
        " '_6',\n",
        " '_7',\n",
        " '_8',\n",
        " '_9',\n",
        " '_10',\n",
        " '_11',\n",
        " '_12',\n",
        " '_13']\n",
        "\n",
        "# Create columns from feature names\n",
        "wine_data = spark.createDataFrame(data, wine_cols)\n",
        "\n",
        "# Assemble features into a single vector\n",
        "assembler = VectorAssembler(inputCols=wine_cols, outputCol=\"features\")\n",
        "df = assembler.transform(wine_data)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLp-kMnPcyHf",
        "outputId": "c45568ee-712d-4634-ad08-f2715fa2cbc4"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----+----+----+-----+----+----+----+----+----+----+----+------+--------------------+\n",
            "|   _1|  _2|  _3|  _4|   _5|  _6|  _7|  _8|  _9| _10| _11| _12|   _13|            features|\n",
            "+-----+----+----+----+-----+----+----+----+----+----+----+----+------+--------------------+\n",
            "|14.23|1.71|2.43|15.6|127.0| 2.8|3.06|0.28|2.29|5.64|1.04|3.92|1065.0|[14.23,1.71,2.43,...|\n",
            "| 13.2|1.78|2.14|11.2|100.0|2.65|2.76|0.26|1.28|4.38|1.05| 3.4|1050.0|[13.2,1.78,2.14,1...|\n",
            "|13.16|2.36|2.67|18.6|101.0| 2.8|3.24| 0.3|2.81|5.68|1.03|3.17|1185.0|[13.16,2.36,2.67,...|\n",
            "|14.37|1.95| 2.5|16.8|113.0|3.85|3.49|0.24|2.18| 7.8|0.86|3.45|1480.0|[14.37,1.95,2.5,1...|\n",
            "|13.24|2.59|2.87|21.0|118.0| 2.8|2.69|0.39|1.82|4.32|1.04|2.93| 735.0|[13.24,2.59,2.87,...|\n",
            "| 14.2|1.76|2.45|15.2|112.0|3.27|3.39|0.34|1.97|6.75|1.05|2.85|1450.0|[14.2,1.76,2.45,1...|\n",
            "|14.39|1.87|2.45|14.6| 96.0| 2.5|2.52| 0.3|1.98|5.25|1.02|3.58|1290.0|[14.39,1.87,2.45,...|\n",
            "|14.06|2.15|2.61|17.6|121.0| 2.6|2.51|0.31|1.25|5.05|1.06|3.58|1295.0|[14.06,2.15,2.61,...|\n",
            "|14.83|1.64|2.17|14.0| 97.0| 2.8|2.98|0.29|1.98| 5.2|1.08|2.85|1045.0|[14.83,1.64,2.17,...|\n",
            "|13.86|1.35|2.27|16.0| 98.0|2.98|3.15|0.22|1.85|7.22|1.01|3.55|1045.0|[13.86,1.35,2.27,...|\n",
            "| 14.1|2.16| 2.3|18.0|105.0|2.95|3.32|0.22|2.38|5.75|1.25|3.17|1510.0|[14.1,2.16,2.3,18...|\n",
            "|14.12|1.48|2.32|16.8| 95.0| 2.2|2.43|0.26|1.57| 5.0|1.17|2.82|1280.0|[14.12,1.48,2.32,...|\n",
            "|13.75|1.73|2.41|16.0| 89.0| 2.6|2.76|0.29|1.81| 5.6|1.15| 2.9|1320.0|[13.75,1.73,2.41,...|\n",
            "|14.75|1.73|2.39|11.4| 91.0| 3.1|3.69|0.43|2.81| 5.4|1.25|2.73|1150.0|[14.75,1.73,2.39,...|\n",
            "|14.38|1.87|2.38|12.0|102.0| 3.3|3.64|0.29|2.96| 7.5| 1.2| 3.0|1547.0|[14.38,1.87,2.38,...|\n",
            "|13.63|1.81| 2.7|17.2|112.0|2.85|2.91| 0.3|1.46| 7.3|1.28|2.88|1310.0|[13.63,1.81,2.7,1...|\n",
            "| 14.3|1.92|2.72|20.0|120.0| 2.8|3.14|0.33|1.97| 6.2|1.07|2.65|1280.0|[14.3,1.92,2.72,2...|\n",
            "|13.83|1.57|2.62|20.0|115.0|2.95| 3.4| 0.4|1.72| 6.6|1.13|2.57|1130.0|[13.83,1.57,2.62,...|\n",
            "|14.19|1.59|2.48|16.5|108.0| 3.3|3.93|0.32|1.86| 8.7|1.23|2.82|1680.0|[14.19,1.59,2.48,...|\n",
            "|13.64| 3.1|2.56|15.2|116.0| 2.7|3.03|0.17|1.66| 5.1|0.96|3.36| 845.0|[13.64,3.1,2.56,1...|\n",
            "+-----+----+----+----+-----+----+----+----+----+----+----+----+------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a KMeans model with 2 clusters\n",
        "kmeans = KMeans(k=3)\n",
        "\n",
        "# Train the model on the data\n",
        "model = kmeans.fit(df)\n",
        "\n",
        "# Make predictions on the data\n",
        "predictions = model.transform(df)\n",
        "\n",
        "# Print the predictions\n",
        "predictions.show()\n",
        "\n",
        "# Stop the SparkSession\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-2rq34EdZiW",
        "outputId": "8e947d39-ea0e-4bf5-e49c-394645946344"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----+----+----+-----+----+----+----+----+----+----+----+------+--------------------+----------+\n",
            "|   _1|  _2|  _3|  _4|   _5|  _6|  _7|  _8|  _9| _10| _11| _12|   _13|            features|prediction|\n",
            "+-----+----+----+----+-----+----+----+----+----+----+----+----+------+--------------------+----------+\n",
            "|14.23|1.71|2.43|15.6|127.0| 2.8|3.06|0.28|2.29|5.64|1.04|3.92|1065.0|[14.23,1.71,2.43,...|         0|\n",
            "| 13.2|1.78|2.14|11.2|100.0|2.65|2.76|0.26|1.28|4.38|1.05| 3.4|1050.0|[13.2,1.78,2.14,1...|         0|\n",
            "|13.16|2.36|2.67|18.6|101.0| 2.8|3.24| 0.3|2.81|5.68|1.03|3.17|1185.0|[13.16,2.36,2.67,...|         0|\n",
            "|14.37|1.95| 2.5|16.8|113.0|3.85|3.49|0.24|2.18| 7.8|0.86|3.45|1480.0|[14.37,1.95,2.5,1...|         0|\n",
            "|13.24|2.59|2.87|21.0|118.0| 2.8|2.69|0.39|1.82|4.32|1.04|2.93| 735.0|[13.24,2.59,2.87,...|         1|\n",
            "| 14.2|1.76|2.45|15.2|112.0|3.27|3.39|0.34|1.97|6.75|1.05|2.85|1450.0|[14.2,1.76,2.45,1...|         0|\n",
            "|14.39|1.87|2.45|14.6| 96.0| 2.5|2.52| 0.3|1.98|5.25|1.02|3.58|1290.0|[14.39,1.87,2.45,...|         0|\n",
            "|14.06|2.15|2.61|17.6|121.0| 2.6|2.51|0.31|1.25|5.05|1.06|3.58|1295.0|[14.06,2.15,2.61,...|         0|\n",
            "|14.83|1.64|2.17|14.0| 97.0| 2.8|2.98|0.29|1.98| 5.2|1.08|2.85|1045.0|[14.83,1.64,2.17,...|         0|\n",
            "|13.86|1.35|2.27|16.0| 98.0|2.98|3.15|0.22|1.85|7.22|1.01|3.55|1045.0|[13.86,1.35,2.27,...|         0|\n",
            "| 14.1|2.16| 2.3|18.0|105.0|2.95|3.32|0.22|2.38|5.75|1.25|3.17|1510.0|[14.1,2.16,2.3,18...|         0|\n",
            "|14.12|1.48|2.32|16.8| 95.0| 2.2|2.43|0.26|1.57| 5.0|1.17|2.82|1280.0|[14.12,1.48,2.32,...|         0|\n",
            "|13.75|1.73|2.41|16.0| 89.0| 2.6|2.76|0.29|1.81| 5.6|1.15| 2.9|1320.0|[13.75,1.73,2.41,...|         0|\n",
            "|14.75|1.73|2.39|11.4| 91.0| 3.1|3.69|0.43|2.81| 5.4|1.25|2.73|1150.0|[14.75,1.73,2.39,...|         0|\n",
            "|14.38|1.87|2.38|12.0|102.0| 3.3|3.64|0.29|2.96| 7.5| 1.2| 3.0|1547.0|[14.38,1.87,2.38,...|         0|\n",
            "|13.63|1.81| 2.7|17.2|112.0|2.85|2.91| 0.3|1.46| 7.3|1.28|2.88|1310.0|[13.63,1.81,2.7,1...|         0|\n",
            "| 14.3|1.92|2.72|20.0|120.0| 2.8|3.14|0.33|1.97| 6.2|1.07|2.65|1280.0|[14.3,1.92,2.72,2...|         0|\n",
            "|13.83|1.57|2.62|20.0|115.0|2.95| 3.4| 0.4|1.72| 6.6|1.13|2.57|1130.0|[13.83,1.57,2.62,...|         0|\n",
            "|14.19|1.59|2.48|16.5|108.0| 3.3|3.93|0.32|1.86| 8.7|1.23|2.82|1680.0|[14.19,1.59,2.48,...|         0|\n",
            "|13.64| 3.1|2.56|15.2|116.0| 2.7|3.03|0.17|1.66| 5.1|0.96|3.36| 845.0|[13.64,3.1,2.56,1...|         1|\n",
            "+-----+----+----+----+-----+----+----+----+----+----+----+----+------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}