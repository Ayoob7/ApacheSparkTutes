{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "metadata": {
        "id": "TD1ZLO2-7-1c",
        "outputId": "f31c915a-1066-4da2-9aa8-84035536569f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488493 sha256=cfeefc20829c0e1262710043683abe7fd0302225c4e2b3ef2cf454560acffc92\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n",
            "The following additional packages will be installed:\n",
            "  libxtst6 openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra fonts-nanum fonts-ipafont-gothic\n",
            "  fonts-ipafont-mincho fonts-wqy-microhei fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  libxtst6 openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 3 newly installed, 0 to remove and 38 not upgraded.\n",
            "Need to get 39.7 MB of archives.\n",
            "After this operation, 144 MB of additional disk space will be used.\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "(Reading database ... 121752 files and directories currently installed.)\n",
            "Preparing to unpack .../libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u392-ga-1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u392-ga-1~22.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u392-ga-1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u392-ga-1~22.04) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u392-ga-1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u392-ga-1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "import pyspark.sql  as pyspark_sql\n",
        "import pyspark.sql.types as pyspark_types\n",
        "import pyspark.sql.functions  as pyspark_functions\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql.functions import row_number, desc"
      ],
      "metadata": {
        "id": "coJ_2iHiBBMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the session\n",
        "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
        "\n",
        "# create the context\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = pyspark_sql.SparkSession.builder.getOrCreate()"
      ],
      "metadata": {
        "id": "5SgihN4H8BST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing pyspark\n",
        "from pyspark.sql.window import Window\n",
        "import pyspark\n",
        "\n",
        "# importing sparksession\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "# sample data for dataframe\n",
        "sampleData = ((101, \"Ram\", \"Biology\", 80),\n",
        "\t\t\t(103, \"Meena\", \"Social Science\", 78),\n",
        "\t\t\t(104, \"Robin\", \"Sanskrit\", 58),\n",
        "\t\t\t(102, \"Kunal\", \"Phisycs\", 89),\n",
        "\t\t\t(101, \"Ram\", \"Biology\", 80),\n",
        "\t\t\t(106, \"Srishti\", \"Maths\", 70),\n",
        "\t\t\t(108, \"Jeny\", \"Physics\", 75),\n",
        "\t\t\t(107, \"Hitesh\", \"Maths\", 88),\n",
        "\t\t\t(109, \"Kailash\", \"Maths\", 90),\n",
        "\t\t\t(105, \"Sharad\", \"Social Science\", 84)\n",
        "\t\t\t)\n",
        "\n",
        "# column names for dataframe\n",
        "columns = [\"Roll_No\", \"Student_Name\", \"Subject\", \"Marks\"]\n",
        "\n",
        "# creating the dataframe df\n",
        "df2 = spark.createDataFrame(data=sampleData,\n",
        "\t\t\t\t\t\t\tschema=columns)\n",
        "\n",
        "# importing window from pyspark.sql.window\n",
        "\n",
        "# creating a window partition of dataframe\n",
        "windowPartition = Window.partitionBy(\"Subject\").orderBy(desc(\"Marks\"))\n",
        "\n",
        "# print schema\n",
        "df2.printSchema()\n",
        "\n",
        "# show df\n",
        "df2.show()"
      ],
      "metadata": {
        "id": "H1j9poN070M_",
        "outputId": "3da63f3e-5480-4ee7-c7d2-58dc603073bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Roll_No: long (nullable = true)\n",
            " |-- Student_Name: string (nullable = true)\n",
            " |-- Subject: string (nullable = true)\n",
            " |-- Marks: long (nullable = true)\n",
            "\n",
            "+-------+------------+--------------+-----+\n",
            "|Roll_No|Student_Name|       Subject|Marks|\n",
            "+-------+------------+--------------+-----+\n",
            "|    101|         Ram|       Biology|   80|\n",
            "|    103|       Meena|Social Science|   78|\n",
            "|    104|       Robin|      Sanskrit|   58|\n",
            "|    102|       Kunal|       Phisycs|   89|\n",
            "|    101|         Ram|       Biology|   80|\n",
            "|    106|     Srishti|         Maths|   70|\n",
            "|    108|        Jeny|       Physics|   75|\n",
            "|    107|      Hitesh|         Maths|   88|\n",
            "|    109|     Kailash|         Maths|   90|\n",
            "|    105|      Sharad|Social Science|   84|\n",
            "+-------+------------+--------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# importing row_number() from pyspark.sql.functions\n",
        "from pyspark.sql.functions import row_number, desc\n",
        "\n",
        "# applying the row_number() function\n",
        "df2.withColumn(\"row_number\",\n",
        "               row_number().over(windowPartition)).show()"
      ],
      "metadata": {
        "id": "MT42jJFaBH9y",
        "outputId": "93c1e8af-b14d-4d44-d124-4bcd6971758c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+--------------+-----+----------+\n",
            "|Roll_No|Student_Name|       Subject|Marks|row_number|\n",
            "+-------+------------+--------------+-----+----------+\n",
            "|    101|         Ram|       Biology|   80|         1|\n",
            "|    101|         Ram|       Biology|   80|         2|\n",
            "|    109|     Kailash|         Maths|   90|         1|\n",
            "|    107|      Hitesh|         Maths|   88|         2|\n",
            "|    106|     Srishti|         Maths|   70|         3|\n",
            "|    102|       Kunal|       Phisycs|   89|         1|\n",
            "|    108|        Jeny|       Physics|   75|         1|\n",
            "|    104|       Robin|      Sanskrit|   58|         1|\n",
            "|    105|      Sharad|Social Science|   84|         1|\n",
            "|    103|       Meena|Social Science|   78|         2|\n",
            "+-------+------------+--------------+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# importing rank() from pyspark.sql.functions\n",
        "from pyspark.sql.functions import rank\n",
        "\n",
        "# applying the rank() function\n",
        "df2.withColumn(\"rank\", rank().over(windowPartition)) \\\n",
        "    .show()"
      ],
      "metadata": {
        "id": "JSr1CN5qBRN7",
        "outputId": "3babd61d-ca9f-4580-95a9-f8bc61b6f2f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+--------------+-----+----+\n",
            "|Roll_No|Student_Name|       Subject|Marks|rank|\n",
            "+-------+------------+--------------+-----+----+\n",
            "|    101|         Ram|       Biology|   80|   1|\n",
            "|    101|         Ram|       Biology|   80|   1|\n",
            "|    109|     Kailash|         Maths|   90|   1|\n",
            "|    107|      Hitesh|         Maths|   88|   2|\n",
            "|    106|     Srishti|         Maths|   70|   3|\n",
            "|    102|       Kunal|       Phisycs|   89|   1|\n",
            "|    108|        Jeny|       Physics|   75|   1|\n",
            "|    104|       Robin|      Sanskrit|   58|   1|\n",
            "|    105|      Sharad|Social Science|   84|   1|\n",
            "|    103|       Meena|Social Science|   78|   2|\n",
            "+-------+------------+--------------+-----+----+\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}